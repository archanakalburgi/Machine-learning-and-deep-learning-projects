{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-U4ITqSURn0",
        "outputId": "9e792f8d-3b4d-424a-e9ec-81e17044772d"
      },
      "source": [
        "!pip install imbalanced-learn\n",
        "!pip install torchinfo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBnyDta1VFZn",
        "outputId": "8320b7cf-75bc-49a1-d5f1-f44f3d396cc8"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import pandas as pd\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import torch\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE,SMOTENC\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pprint import pprint"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhLDjr2EVGDr"
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02vQu9lcVJjZ",
        "outputId": "d02b03bf-abba-4026-84eb-56dd047d9417"
      },
      "source": [
        "# fix random number\n",
        "\n",
        "random_seed = 7777\n",
        "# seed(random_seed)\n",
        "\n",
        "torch.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f95115b3510>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrulY1HXVNe8"
      },
      "source": [
        "class news_dataset(Dataset):\n",
        "    def __init__(self,x,y):\n",
        "        self.x = torch.from_numpy(x).float()\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.x.size()[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiKka4RhVQ9o"
      },
      "source": [
        "def train_model(model, train_dataset, test_dataset, device, optimizer,\n",
        "                epochs=50,\n",
        "                lr=0.0005, \n",
        "                batch_size=256, \n",
        "                regularizer=0,\n",
        "                criterion=nn.CrossEntropyLoss()                \n",
        "                ):  # add more parameters if needed\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "    \n",
        "    model = model.to(device)\n",
        "\n",
        "    train_history = {'train_loss': [],\n",
        "                    'train_acc': [],\n",
        "                    'test_loss': [],\n",
        "                    'test_acc': []}\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        test_loss = 0\n",
        "        test_acc = 0\n",
        "        for x,y in train_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "\n",
        "            outputs = model(x)\n",
        "            score, pred = torch.max(outputs, 1) \n",
        "            \n",
        "\n",
        "            cur_train_loss = criterion(outputs, y)\n",
        "         \n",
        "            cur_train_acc = (pred == y).sum().float() / batch_size\n",
        "\n",
        "            cur_train_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad() \n",
        "\n",
        "            train_loss += cur_train_loss\n",
        "            train_acc += cur_train_acc\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                # move\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                # predict\n",
        "                outputs = model(x)\n",
        "                score, pred = torch.max(outputs, 1)\n",
        "                cur_test_loss = criterion(outputs, y)\n",
        "                cur_test_acc = (pred == y).sum().float() / batch_size \n",
        "                # loss and acc\n",
        "                test_loss += cur_test_loss\n",
        "                test_acc += cur_test_acc\n",
        "\n",
        "        train_loss = (train_loss/len(train_loader)).item()\n",
        "        train_acc = train_acc/len(train_loader)\n",
        "        val_loss = (test_loss/len(test_loader)).item()\n",
        "        val_acc = test_acc/len(test_loader)\n",
        "\n",
        "        train_history['train_loss'].append(train_loss)\n",
        "        train_history['train_acc'].append(train_acc)\n",
        "        train_history['test_loss'].append(val_loss)\n",
        "        train_history['test_acc'].append(val_acc)\n",
        "        print(f\"Epoch:{epoch + 1} / {epochs}, train loss:{train_loss:.5f} train_acc:{train_acc:.5f}, valid loss:{val_loss:.5f} valid acc:{val_acc:.5f}\")\n",
        "        # display.clear_output(wait=True)\n",
        " \n",
        "    return train_history"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSSaH3PDVTVi",
        "outputId": "c225a9d3-cfd9-4c2d-a825-2069d8206f1c"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# Our vectorized training data, puts them all on to a same dimension\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "X_resampled, y_resampled = ros.fit_resample(x_train, train_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lccKqDVAWe4k"
      },
      "source": [
        "y_test = np.array(train_labels)\n",
        "train_dataset = news_dataset(X_resampled, y_resampled)\n",
        "test_dataset = news_dataset(x_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOTL3KrqVWiy"
      },
      "source": [
        "class linear_model_with_regularizer2(nn.Module):\n",
        "    def __init__(self, hidden_l1,dropout_ratio=0):  # add more parameters if needsed\n",
        "        \n",
        "       # add your code\n",
        "        super(linear_model_with_regularizer2, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_ratio),\n",
        "            nn.Linear(in_features=10000, out_features=hidden_l1),\n",
        "            nn.Softmax(),\n",
        "            nn.Dropout(p=dropout_ratio),\n",
        "            nn.Linear(in_features=hidden_l1, out_features=46)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gueGvs7FWmbu",
        "outputId": "d1b9870a-c57c-4561-a069-2cd689c64b06"
      },
      "source": [
        "lr=0.005\n",
        "regularizer=0\n",
        "modelr = linear_model_with_regularizer2(hidden_l1=128,dropout_ratio=0.5)\n",
        "optimizer = torch.optim.Adam(modelr.parameters(), lr=lr, weight_decay=regularizer)\n",
        "hista = train_model(modelr, train_dataset, test_dataset, device, epochs=50, optimizer=optimizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 / 50, train loss:4.35318 train_acc:0.01959, valid loss:3.65848 valid acc:0.00304\n",
            "Epoch:2 / 50, train loss:3.79885 train_acc:0.01650, valid loss:3.97640 valid acc:0.00738\n",
            "Epoch:3 / 50, train loss:3.69075 train_acc:0.02514, valid loss:3.79351 valid acc:0.09288\n",
            "Epoch:4 / 50, train loss:3.56104 train_acc:0.02719, valid loss:3.81738 valid acc:0.10156\n",
            "Epoch:5 / 50, train loss:3.46429 train_acc:0.03150, valid loss:3.86212 valid acc:0.09549\n",
            "Epoch:6 / 50, train loss:3.38983 train_acc:0.03679, valid loss:3.90443 valid acc:0.00651\n",
            "Epoch:7 / 50, train loss:3.32318 train_acc:0.03684, valid loss:3.91408 valid acc:0.01649\n",
            "Epoch:8 / 50, train loss:3.26117 train_acc:0.03513, valid loss:3.91209 valid acc:0.03516\n",
            "Epoch:9 / 50, train loss:3.22346 train_acc:0.03439, valid loss:3.94758 valid acc:0.03255\n",
            "Epoch:10 / 50, train loss:3.18112 train_acc:0.03438, valid loss:3.95684 valid acc:0.03038\n",
            "Epoch:11 / 50, train loss:3.14859 train_acc:0.03650, valid loss:3.92460 valid acc:0.05903\n",
            "Epoch:12 / 50, train loss:3.11758 train_acc:0.03970, valid loss:3.93929 valid acc:0.07422\n",
            "Epoch:13 / 50, train loss:3.09713 train_acc:0.04840, valid loss:3.90952 valid acc:0.08116\n",
            "Epoch:14 / 50, train loss:3.07717 train_acc:0.04764, valid loss:3.94228 valid acc:0.06554\n",
            "Epoch:15 / 50, train loss:3.05840 train_acc:0.04718, valid loss:3.90066 valid acc:0.09245\n",
            "Epoch:16 / 50, train loss:3.04704 train_acc:0.04903, valid loss:3.94766 valid acc:0.07986\n",
            "Epoch:17 / 50, train loss:3.03741 train_acc:0.05819, valid loss:3.98035 valid acc:0.07595\n",
            "Epoch:18 / 50, train loss:3.02277 train_acc:0.05527, valid loss:3.93003 valid acc:0.08116\n",
            "Epoch:19 / 50, train loss:2.99657 train_acc:0.06487, valid loss:4.01742 valid acc:0.07075\n",
            "Epoch:20 / 50, train loss:2.98134 train_acc:0.07885, valid loss:4.07116 valid acc:0.09766\n",
            "Epoch:21 / 50, train loss:2.96136 train_acc:0.08260, valid loss:4.05403 valid acc:0.08984\n",
            "Epoch:22 / 50, train loss:2.93935 train_acc:0.08515, valid loss:4.13808 valid acc:0.09245\n",
            "Epoch:23 / 50, train loss:2.92169 train_acc:0.08899, valid loss:4.13877 valid acc:0.11241\n",
            "Epoch:24 / 50, train loss:2.90332 train_acc:0.09309, valid loss:4.25124 valid acc:0.11892\n",
            "Epoch:25 / 50, train loss:2.88377 train_acc:0.10061, valid loss:4.35090 valid acc:0.12630\n",
            "Epoch:26 / 50, train loss:2.86962 train_acc:0.10622, valid loss:4.35916 valid acc:0.10677\n",
            "Epoch:27 / 50, train loss:2.84936 train_acc:0.11102, valid loss:4.49114 valid acc:0.12413\n",
            "Epoch:28 / 50, train loss:2.82790 train_acc:0.11410, valid loss:4.60098 valid acc:0.10373\n",
            "Epoch:29 / 50, train loss:2.80848 train_acc:0.11973, valid loss:4.64654 valid acc:0.11892\n",
            "Epoch:30 / 50, train loss:2.78597 train_acc:0.12365, valid loss:4.55856 valid acc:0.11719\n",
            "Epoch:31 / 50, train loss:2.77561 train_acc:0.13001, valid loss:4.73945 valid acc:0.12457\n",
            "Epoch:32 / 50, train loss:2.76004 train_acc:0.13750, valid loss:4.88831 valid acc:0.10460\n",
            "Epoch:33 / 50, train loss:2.73160 train_acc:0.14840, valid loss:4.71568 valid acc:0.14236\n",
            "Epoch:34 / 50, train loss:2.70953 train_acc:0.16020, valid loss:4.84093 valid acc:0.13411\n",
            "Epoch:35 / 50, train loss:2.69912 train_acc:0.16573, valid loss:4.99535 valid acc:0.12413\n",
            "Epoch:36 / 50, train loss:2.69642 train_acc:0.16766, valid loss:5.06128 valid acc:0.13368\n",
            "Epoch:37 / 50, train loss:2.66875 train_acc:0.17610, valid loss:5.06533 valid acc:0.14062\n",
            "Epoch:38 / 50, train loss:2.65591 train_acc:0.17776, valid loss:5.15725 valid acc:0.14410\n",
            "Epoch:39 / 50, train loss:2.64611 train_acc:0.18571, valid loss:5.35260 valid acc:0.13715\n",
            "Epoch:40 / 50, train loss:2.63508 train_acc:0.19005, valid loss:5.31041 valid acc:0.13455\n",
            "Epoch:41 / 50, train loss:2.61745 train_acc:0.19461, valid loss:5.42615 valid acc:0.11675\n",
            "Epoch:42 / 50, train loss:2.58420 train_acc:0.20080, valid loss:5.47828 valid acc:0.12847\n",
            "Epoch:43 / 50, train loss:2.55970 train_acc:0.20431, valid loss:5.45422 valid acc:0.13108\n",
            "Epoch:44 / 50, train loss:2.53013 train_acc:0.21298, valid loss:5.67222 valid acc:0.12413\n",
            "Epoch:45 / 50, train loss:2.51637 train_acc:0.22007, valid loss:5.62126 valid acc:0.13194\n",
            "Epoch:46 / 50, train loss:2.48215 train_acc:0.23010, valid loss:5.63643 valid acc:0.13759\n",
            "Epoch:47 / 50, train loss:2.46929 train_acc:0.23482, valid loss:5.91201 valid acc:0.12023\n",
            "Epoch:48 / 50, train loss:2.44823 train_acc:0.24028, valid loss:5.96533 valid acc:0.14366\n",
            "Epoch:49 / 50, train loss:2.41260 train_acc:0.24739, valid loss:6.08229 valid acc:0.13325\n",
            "Epoch:50 / 50, train loss:2.38348 train_acc:0.25289, valid loss:6.07075 valid acc:0.14366\n"
          ]
        }
      ]
    }
  ]
}