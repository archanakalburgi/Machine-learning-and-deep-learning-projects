{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a7c76ba-f996-4c03-8115-1ff162a1d193",
      "metadata": {
        "id": "3a7c76ba-f996-4c03-8115-1ff162a1d193"
      },
      "source": [
        "# CS 584 Assignment 4 -- Sequence to Sequence Models\n",
        "\n",
        "#### Name: Archana Kalburgi\n",
        "#### Stevens ID: 10469491"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3049c644-1868-4884-9092-c386a2b8f796",
      "metadata": {
        "id": "3049c644-1868-4884-9092-c386a2b8f796"
      },
      "source": [
        "## In this assignment, you are required to follow the steps below:\n",
        "1. Review the lecture slides.\n",
        "2. Implement the seq2seq (translation) model.\n",
        "\n",
        "**Before you start**\n",
        "- Please read the code very carefully.\n",
        "- Install these packages using the following command.\n",
        "```console\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "- It's better to train the Tensorflow model with GPU and CUDA. If they are not available on your local machine, please consider Google CoLab. You can check `CoLab.md` in this assignments.\n",
        "- You are **NOT** allowed to use other packages unless otherwise specified.\n",
        "- You are **ONLY** allowed to edit the code between `# Start your code here` and `# End` for each block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "RxyMH_t59Epe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxyMH_t59Epe",
        "outputId": "9443a6e2-15f7-4c23-e77e-cf281c75d773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eac7acc6-10d0-45b5-9372-b1f51ea43592",
      "metadata": {
        "id": "eac7acc6-10d0-45b5-9372-b1f51ea43592"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "def print_line(*args):\n",
        "    \"\"\" Inline print and go to the begining of line\n",
        "    \"\"\"\n",
        "    args1 = [str(arg) for arg in args]\n",
        "    str_ = ' '.join(args1)\n",
        "    print('\\r' + str_, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "55b388bc-1b41-40a9-93ae-536d1364e4d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b388bc-1b41-40a9-93ae-536d1364e4d7",
        "outputId": "c0cfb149-8d5d-40fb-eb73-64e9db6e6184",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2.7.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (2.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 7)) (0.18.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (0.70.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2022.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (4.13.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (0.11.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (4.9.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (2.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.27.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.9.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.9.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (2.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 7)) (2.7.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt (line 1)) (2022.6)\n"
          ]
        }
      ],
      "source": [
        "! pip install -r \"/content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "122f2824-a6f3-4ef3-a50c-197f841b7386",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "122f2824-a6f3-4ef3-a50c-197f841b7386",
        "outputId": "9c200084-d517-44f2-dc15-2aa13ef3f39a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# If you are going to use GPU, make sure the GPU in in the output\n",
        "tf.config.list_physical_devices('GPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "39c87f0d-f4a4-4250-87ce-9e06c97c5a11",
      "metadata": {
        "id": "39c87f0d-f4a4-4250-87ce-9e06c97c5a11"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Union, Dict\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02036c6-d232-445f-b04c-6293a7521438",
      "metadata": {
        "id": "c02036c6-d232-445f-b04c-6293a7521438"
      },
      "source": [
        "## 1. Data preparation (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "429f2127-8978-421c-a76b-07c87eab3801",
      "metadata": {
        "id": "429f2127-8978-421c-a76b-07c87eab3801"
      },
      "source": [
        "### 1.1 Load and describe data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822e87bb-a5f3-46b2-9848-2a2965ea87f1",
      "metadata": {
        "id": "822e87bb-a5f3-46b2-9848-2a2965ea87f1"
      },
      "source": [
        "Here, we use the [iwslt2017](https://huggingface.co/datasets/iwslt2017) dataset. More specifically, this translation task is from French to English: fr-en."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aad9571f-885c-4b16-bf20-39e9431305a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "233335dd716e499aa4434216e56bcc29",
            "fc31a2a40fc84c48b817d2add157747e",
            "31633a0cf6c84beb9c397666f856e45c",
            "e343b79e8e1c45ff88f7958e5abf7636",
            "9218b33f8a5446f5b21eddefccb68b76",
            "807566af41b44a089264a5e3ece63e98",
            "79177f1279684b7ab416c4d4ace8beb3",
            "62a233c673f745159fa9e79bd639fa1e",
            "504b22b39b5745109e34a8a787f3af66",
            "2a528f37252a4feead4e9b1879c0d03f",
            "7f4a1a68a75f47149e748db8a4a7c645"
          ]
        },
        "id": "aad9571f-885c-4b16-bf20-39e9431305a5",
        "outputId": "7f5a040d-2e90-49f9-86ae-cbce943eb8b3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset iwslt2017 (/content/a4-data/dataset/iwslt2017/iwslt2017-en-fr/1.0.0/03ce9110373117c6f6687719f49f269486a8cd49dcad2527993a316cd4b6ad49)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "233335dd716e499aa4434216e56bcc29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "# The load_dataset function is provided by the huggingface datasets\n",
        "# https://huggingface.co/docs/datasets/index\n",
        "\n",
        "\n",
        "dataset_path = os.path.join('a4-data', 'dataset')\n",
        "dataset = load_dataset('iwslt2017', 'iwslt2017-en-fr', cache_dir=dataset_path, ignore_verifications=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf8e8e6b-a386-4e31-bf2e-3f8dc79bec0b",
      "metadata": {
        "id": "cf8e8e6b-a386-4e31-bf2e-3f8dc79bec0b"
      },
      "source": [
        "Let's first print some basic statistics of this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b62dbd50-c8ea-4168-9ba5-063e629e1ba7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b62dbd50-c8ea-4168-9ba5-063e629e1ba7",
        "outputId": "91ee06b1-6057-46f6-a343-5701dfc29ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 232825\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 8597\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 890\n",
            "    })\n",
            "})\n",
            "232825 890 8597\n"
          ]
        }
      ],
      "source": [
        "print(dataset)\n",
        "print(len(dataset['train']['translation']), len(dataset['validation']['translation']), len(dataset['test']['translation']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f3477aaa-1394-45b3-8cd9-7e99b75a6b52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3477aaa-1394-45b3-8cd9-7e99b75a6b52",
        "outputId": "f0c2b2a2-5fde-476b-99df-67161d97f29c",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\",\n",
              "  'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"},\n",
              " {'en': 'I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.',\n",
              "  'fr': \"J'ai été très impressionné par cette conférence, et je tiens à vous remercier tous pour vos nombreux et sympathiques commentaires sur ce que j'ai dit l'autre soir.\"},\n",
              " {'en': 'And I say that sincerely, partly because  Put yourselves in my position.',\n",
              "  'fr': \"Et je dis çà sincèrement, en autres parce que --Faux sanglot-- j'en ai besoin ! --Rires-- Mettez-vous à ma place!\"},\n",
              " {'en': 'I flew on Air Force Two for eight years.',\n",
              "  'fr': \"J'ai volé avec Air Force 2 pendant huit ans.\"},\n",
              " {'en': 'Now I have to take off my shoes or boots to get on an airplane!',\n",
              "  'fr': \"Et maintenant, je dois enlever mes chaussures pour monter à bord d'un avion !\"}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train']['translation'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5d1c46a0-62b1-4d06-895c-7d08a2f39e76",
      "metadata": {
        "id": "5d1c46a0-62b1-4d06-895c-7d08a2f39e76"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "# The tokenizer is provided by the huggingface tokenizers\n",
        "# https://huggingface.co/docs/tokenizers/index\n",
        "# Here, I already pretrained a BPE tokenizer and you can simply load the json\n",
        "# The token numbers of both English and French are 10,000\n",
        "# All tokens should be lower-case.\n",
        "\n",
        "\n",
        "en_tokenizer = Tokenizer.from_file('/content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/a4-data/en_tokenizer.json')\n",
        "fr_tokenizer = Tokenizer.from_file('/content/drive/MyDrive/nlp_assignments/Assignment4_kalburgi_Archana/a4-data/fr_tokenizer.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "056f7703-8836-4cfb-80ff-4e87f7dfa1dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "056f7703-8836-4cfb-80ff-4e87f7dfa1dc",
        "outputId": "a53093ce-0bc8-4a25-a718-a7efe2292797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 122, 279, 4987, 17, 1]\n",
            "['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "encoding = en_tokenizer.encode(\"i like sports.\")\n",
        "print(encoding.ids)\n",
        "print(encoding.tokens)\n",
        "# >>> [0, 122, 279, 4987, 17, 1] \n",
        "# >>> ['<s>', 'Ġi', 'Ġlike', 'Ġsports', '.', '</s>']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a8523cc-08c4-451c-b7a8-76322c543e6e",
      "metadata": {
        "id": "2a8523cc-08c4-451c-b7a8-76322c543e6e"
      },
      "source": [
        "Extract English and French sentences for training, validation, and test sets.\n",
        "\n",
        "Note: Every sentence is lower-case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "abd5359d-1993-4f1f-ac6b-6db3911713ef",
      "metadata": {
        "id": "abd5359d-1993-4f1f-ac6b-6db3911713ef"
      },
      "outputs": [],
      "source": [
        "train_en_sentences, train_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['train']['translation']])\n",
        "valid_en_sentences, valid_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['validation']['translation']])\n",
        "test_en_sentences, test_fr_sentences = zip(*[(pair['en'].lower(), pair['fr'].lower()) for pair in dataset['test']['translation']])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3530a74f-e2c7-493d-8fa0-ce8c925f973d",
      "metadata": {
        "id": "3530a74f-e2c7-493d-8fa0-ce8c925f973d"
      },
      "source": [
        "### 1.2 Encode data (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a45e2d57-8dc5-4f41-988c-1b87b4bd42b6",
      "metadata": {
        "id": "a45e2d57-8dc5-4f41-988c-1b87b4bd42b6"
      },
      "outputs": [],
      "source": [
        "def encode(tokenizer: 'Tokenizer', sentences: List[str]) -> List[List[int]]:\n",
        "    \"\"\" Encode the sentences with the pretrained tokenizer.\n",
        "        You can directly call `tokenizer.encode()` to encode the sentences.\n",
        "        It will automatically add the <s> and </s> token.\n",
        "        \n",
        "        Note: Please be carefull with the return value of the encode function.\n",
        "    \n",
        "    Args:\n",
        "        tokenizer: A pretrained en/fr tokenizer\n",
        "        sentences: A list of strings\n",
        "    Return:\n",
        "        sent_token_ids: A list of token ids\n",
        "    \"\"\"\n",
        "    sent_token_ids = []\n",
        "    n = len(sentences)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        if i % 100 == 0 or i == n - 1:\n",
        "            print_line('Encoding with Tokenizer:', (i + 1), '/', n)\n",
        "        # Start your code here\n",
        "        sentence_id = tokenizer.encode(sentence).ids\n",
        "        sent_token_ids.append(sentence_id)\n",
        "        # End\n",
        "    print_line('\\n')\n",
        "    return sent_token_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "19675167-bc6d-44f0-920e-284acddc7e14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19675167-bc6d-44f0-920e-284acddc7e14",
        "outputId": "46a3832d-9ec7-43ed-f83b-78f871e3dc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en\n",
            "Encoding with Tokenizer: 232825 / 232825\n",
            "Encoding with Tokenizer: 890 / 890\n",
            "Encoding with Tokenizer: 8597 / 8597\n",
            "fr\n",
            "Encoding with Tokenizer: 232825 / 232825\n",
            "Encoding with Tokenizer: 890 / 890\n",
            "Encoding with Tokenizer: 8597 / 8597\n"
          ]
        }
      ],
      "source": [
        "print('en')\n",
        "train_en = encode(en_tokenizer, train_en_sentences)\n",
        "valid_en = encode(en_tokenizer, valid_en_sentences)\n",
        "test_en = encode(en_tokenizer, test_en_sentences)\n",
        "print('fr')\n",
        "train_fr = encode(fr_tokenizer, train_fr_sentences)\n",
        "valid_fr = encode(fr_tokenizer, valid_fr_sentences)\n",
        "test_fr = encode(fr_tokenizer, test_fr_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b0986e-8851-4e12-aa30-d683a1459791",
      "metadata": {
        "id": "78b0986e-8851-4e12-aa30-d683a1459791"
      },
      "source": [
        "Check your implementation with an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "53552f30-349e-4204-86f5-78ee42cfe78b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53552f30-349e-4204-86f5-78ee42cfe78b",
        "outputId": "39fa19d3-844b-43aa-e3b1-6ccf8c088b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\", 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. Je suis très reconnaissant.\"}\n",
            "[0, 658, 162, 188, 494, 15, 2843, 17, 138, 165, 178, 2775, 121, 630, 4502, 140, 222, 124, 1930, 140, 625, 140, 185, 2122, 3446, 30, 122, 400, 2576, 5818, 17, 1] [0, 763, 478, 15, 3016, 17, 145, 10, 178, 487, 169, 8981, 152, 1038, 2055, 266, 323, 2425, 220, 1760, 586, 17, 214, 459, 378, 9952, 17, 1]\n",
            " thank you so much, chris. and it's truly a great honor to have the opportunity to come to this stage twice; i'm extremely grateful.  merci beaucoup, chris. c'est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois. je suis très reconnaissant.\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train']['translation'][0])\n",
        "print(train_en[0], train_fr[0])\n",
        "print(en_tokenizer.decode(train_en[0]), fr_tokenizer.decode(train_fr[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82322d84-66f5-4d87-b6cd-41b996e7a0c5",
      "metadata": {
        "id": "82322d84-66f5-4d87-b6cd-41b996e7a0c5"
      },
      "source": [
        "## 2. Sequence to sequence model (40 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a10839-398f-421c-aac3-d189d61c2982",
      "metadata": {
        "id": "29a10839-398f-421c-aac3-d189d61c2982"
      },
      "source": [
        "### 2.1 Encoder (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "92c0cf2c-7a93-4f93-af76-8e702e35929f",
      "metadata": {
        "id": "92c0cf2c-7a93-4f93-af76-8e702e35929f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, GRU, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "\n",
        "class Encoder(Model):\n",
        "    def __init__(self, vocab_size: int, embedding_size: int, units: int):\n",
        "        \"\"\" The encoder model for the src sentences.\n",
        "            It contains an embedding part and a GRU part.\n",
        "        \n",
        "        Args:\n",
        "            vocab_size: The src vocabulary size\n",
        "            embedding_size: The embedding size for the embedding layer\n",
        "            units: Number of hidden units in the RNN (GRU) layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Start your code here\n",
        "        # Note: Please know what the decoder needs from encoder. This determines the parameters of the GRU layer\n",
        "        self.embedding = Embedding(vocab_size, embedding_size) # embedding part \n",
        "        self.gru = GRU(units, return_sequences=True, return_state = True) # gru part \n",
        "        # End\n",
        "\n",
        "    def call(self, src_ids, src_mask):\n",
        "        \"\"\" Encoder forward\n",
        "        Args:\n",
        "            src_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
        "            src_mask: Tensor, (batch_size x max_len), the mask of the src input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
        "        Returns:\n",
        "            enc_output: Tensor, (batch_size x max_len x units), the output of GRU for all timesteps\n",
        "            final_state: Tensor, (batch_size x units), the state of the final valid timestep\n",
        "        \"\"\"\n",
        "        # Start your code here\n",
        "        # Step 1. Retrieve embedding\n",
        "        #      2. GRU\n",
        "        # Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
        "        self.src_ids_embeddings = self.embedding(src_ids)\n",
        "        enc_outputs, final_state = self.gru(inputs = self.src_ids_embeddings, mask=src_mask)\n",
        "        # End\n",
        "        return enc_outputs, final_state\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da95576b-60df-4537-b696-f02bb84507c8",
      "metadata": {
        "id": "da95576b-60df-4537-b696-f02bb84507c8"
      },
      "source": [
        "### 2.2 Decoder (15 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dbd4e882-14d4-4ae5-93a8-58405dd58e82",
      "metadata": {
        "id": "dbd4e882-14d4-4ae5-93a8-58405dd58e82"
      },
      "outputs": [],
      "source": [
        "class Decoder(Model):\n",
        "    def __init__(self, vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
        "        \"\"\" The decoder model for the tgt sentences.\n",
        "            It contains an embedding part, a GRU part, a dropout part, and a classifier part.\n",
        "            \n",
        "        Args:\n",
        "            vocab_size: The tgt vocabulary size\n",
        "            embedding_size: The embedding size for the embedding layer\n",
        "            units: Number of hidden units in the RNN (GRU) layer\n",
        "            dropout_rate: The classifier has a (units x vocab_size) weight. This is a large weight matrix. We apply a dropout layer to avoid overfitting.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Start your code here\n",
        "        # Note: 1. Please correctly set the parameter of GRU\n",
        "        #       2. No softmax here because we will need the sequence to sequence loss later\n",
        "        \n",
        "        self.embedding = Embedding(vocab_size, embedding_size)\n",
        "        self.dropout = Dropout(dropout_rate)\n",
        "        self.gru = GRU(units, return_sequences = True)\n",
        "        self.classifier = Dense(units = vocab_size)\n",
        "    \n",
        "        # End\n",
        "\n",
        "    def call(self, tgt_ids, initial_state, tgt_mask):\n",
        "        \"\"\" Decoder forward.\n",
        "            It is called by decoder(tgt_ids=..., initial_state=..., tgt_mask=...)\n",
        "\n",
        "        Args:\n",
        "            tgt_ids: Tensor, (batch_size x max_len), the token ids of input sentences in a batch\n",
        "            initial_state: Tensor, (batch_size x units), the state of the final valid timestep from the encoder\n",
        "            tgt_mask: Tensor, (batch_size x max_len), the mask of the tgt input. True value in the mask means this timestep is valid, otherwise this timestep is ignored\n",
        "        Return:\n",
        "            dec_outputs: Tensor, (batch_size x max_len x vocab_size), the output of GRU for all timesteps\n",
        "        \"\"\"\n",
        "        # Start your code here\n",
        "        # Step 1. Retrieve embedding\n",
        "        #      2. GRU\n",
        "        #      3. Apply dropout to the GRU output\n",
        "        #      4. Classifier\n",
        "        # Note: Please refer to the calling arguments of GRU: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU#call-arguments\n",
        "        embedded_target_ids = self.embedding(tgt_ids)\n",
        "        dec_outputs = self.gru(inputs = embedded_target_ids, mask=tgt_mask, initial_state = initial_state)\n",
        "        dec_outputs = self.dropout(dec_outputs)\n",
        "        dec_outputs = self.classifier(dec_outputs)\n",
        "        # End\n",
        "        return dec_outputs\n",
        "    \n",
        "    def predict(self, tgt_ids, initial_state):\n",
        "        \"\"\" Decoder prediction.\n",
        "            This is a step in recursive prediction. We use the previous prediction and state to predict current token.\n",
        "            Note that we only need to use the gru_cell instead of GRU becasue we only need to calculate one timestep.\n",
        "            \n",
        "        Args:\n",
        "            tgt_ids: Tensor, (batch_size, ) -> (1, ), the token id of the current timestep in the current sentence.\n",
        "            initial_state: Tensor, (batch_size x units) -> (1 x units), the state of the final valid timestep from the encoder or the previous hidden state in prediction.\n",
        "        Return:\n",
        "            dec_outputs: Tensor, (batch_size x vocab_size) -> (1 x vocab_size), the output of GRU for this timestep.\n",
        "            state: Tensor, (batch_size x units) -> (1 x units), the state of this timestep.\n",
        "        \"\"\"\n",
        "        gru_cell = self.gru.cell\n",
        "        # Start your code here\n",
        "        # Step 1. Retrieve embedding\n",
        "        #      2. GRU Cell, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell#call-arguments\n",
        "        #      3. Classifier (No dropout)\n",
        "        embedded_target_ids = self.embedding(tgt_ids)\n",
        "        dec_outputs, state = gru_cell(inputs = embedded_target_ids, states = initial_state, training = False)\n",
        "        dec_outputs = self.classifier(dec_outputs)\n",
        "        # End\n",
        "        return dec_outputs, state\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1720c69-2fd3-4310-b850-9ce9036bfe23",
      "metadata": {
        "id": "a1720c69-2fd3-4310-b850-9ce9036bfe23"
      },
      "source": [
        "### 2.3 Seq2seq (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f69663d6-bcc9-439e-82fe-a366c71286ab",
      "metadata": {
        "id": "f69663d6-bcc9-439e-82fe-a366c71286ab"
      },
      "outputs": [],
      "source": [
        "class Seq2seq(Model):\n",
        "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, embedding_size: int, units: int, dropout_rate: float):\n",
        "        \"\"\" The sequence to sequence model.\n",
        "            It contains an encoder and a decoder.\n",
        "            \n",
        "        Args:\n",
        "            src_vocab_size: The src vocabulary size\n",
        "            tgt_vocab_size: The tgt vocabulary size\n",
        "            embedding_size: The embedding size for the embedding layer\n",
        "            units: Number of hidden units in the RNN (GRU) layer\n",
        "            dropout_rate: The dropout rate used in the decoder.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Start your code here\n",
        "        self.encoder = Encoder(vocab_size = src_vocab_size, embedding_size = embedding_size, units = units)\n",
        "        self.decoder = Decoder(vocab_size = tgt_vocab_size, embedding_size = embedding_size, units = units, dropout_rate = dropout_rate)\n",
        "        # End\n",
        "\n",
        "    def call(self, src_ids, src_seq_lens, tgt_ids, tgt_seq_lens):\n",
        "        \"\"\" Seq2seq forward (for the loss calculation in training/validation only).\n",
        "            It is called by model(src_ids=..., src_seq_lens=..., tgt_ids=..., tgt_seq_lens=)\n",
        "            Note: In prediction, we will also need to set `training=False`.\n",
        "\n",
        "        Args:\n",
        "            src_ids: Tensor, (batch_size x max_len), the token ids of src sentences in a batch\n",
        "            src_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
        "            tgt_ids: Tensor, (batch_size x max_len), the token ids of tgt sentences in a batch\n",
        "            tgt_seq_lens: Tensor, (batch_size, ), the length of src sentences in a batch\n",
        "        Returns:\n",
        "            dec_outputs: Tensor, (batch_size x max_len x units), the decoder predictions\n",
        "        \"\"\"\n",
        "        # Start your code here\n",
        "        # Step 1. build mask for src and tgt\n",
        "        #      2. encoder forward\n",
        "        #      3. decoder forward\n",
        "        pad_token = fr_tokenizer.token_to_id('<pad>')\n",
        "        src_mask = src_ids != pad_token\n",
        "        tgt_mask = tgt_ids != pad_token\n",
        "        enc_outputs, enc_state = self.encoder(src_ids, src_mask)\n",
        "        dec_outputs = self.decoder(tgt_ids, enc_state, tgt_mask)\n",
        "        # End\n",
        "        return dec_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a240b136-ca49-4fc8-ab34-5bc2516cadad",
      "metadata": {
        "id": "a240b136-ca49-4fc8-ab34-5bc2516cadad",
        "tags": []
      },
      "source": [
        "### 2.4 Seq2seq loss (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "46fac669-188c-4813-9734-ad5d44d406bb",
      "metadata": {
        "id": "46fac669-188c-4813-9734-ad5d44d406bb"
      },
      "outputs": [],
      "source": [
        "from tensorflow_addons.seq2seq import sequence_loss\n",
        "\n",
        "\n",
        "def seq2seq_loss(logits, target, seq_lens):\n",
        "    \"\"\" Calculate the sequence to sequence loss using the sequence_loss from tensorflow\n",
        "    \n",
        "    Args:\n",
        "        logits: Tensor (batch_size x max_seq_len x vocab_size). The output of the RNN model.\n",
        "        target: Tensor (batch_size x max_seq_len). The groud-truth of words.\n",
        "        seq_lens: Tensor (batch_size, ). The real sequence length before padding.\n",
        "    \"\"\"\n",
        "    loss = 0\n",
        "    # Start your code here\n",
        "    # 1. make a sequence mask (batch_size x max_seq_len) using tf.sequence_mask. This is to build a mask with 1 and 0.\n",
        "    #    Entry with 1 is the valid time step without padding. Entry with 0 is the time step with padding. We need to exclude this time step.\n",
        "    # 2. calculate the loss with sequence_loss. Carefully read the documentation of each parameter\n",
        "    seq_mask = tf.sequence_mask(seq_lens, dtype = tf.dtypes.float32)\n",
        "    loss = sequence_loss(logits, target, seq_mask, sum_over_timesteps=False, sum_over_batch=False, average_across_batch=True, average_across_timesteps=True)\n",
        "    # End\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7032d2fb-827f-4132-b128-70babd974f08",
      "metadata": {
        "id": "7032d2fb-827f-4132-b128-70babd974f08",
        "tags": []
      },
      "source": [
        "## 3. Training (50 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ddf45c-adb4-449d-9a5a-052512e5ff97",
      "metadata": {
        "id": "79ddf45c-adb4-449d-9a5a-052512e5ff97",
        "tags": []
      },
      "source": [
        "### 3.1 Pad batch (15 Points)\n",
        "\n",
        "`pad_src_batch`: 5 Points\n",
        "`pad_tgt_batch`: 10 Points\n",
        "\n",
        "Pad the batch to the equal length and make tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ie1t0ee4g0RL",
      "metadata": {
        "id": "ie1t0ee4g0RL"
      },
      "outputs": [],
      "source": [
        "# padded_src = [i + [pad_val]*(max_len - len(i)) for i in src_batch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "xyJHaacTCd2I",
      "metadata": {
        "id": "xyJHaacTCd2I"
      },
      "outputs": [],
      "source": [
        "def helper_function(batch, pad_val, max_length):\n",
        "  result = []\n",
        "  for i in batch:\n",
        "    result.append(i + [pad_val]*(max_length - len(i)))\n",
        "  return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "98d23097-f74d-49cf-8c61-89c60d4b8873",
      "metadata": {
        "id": "98d23097-f74d-49cf-8c61-89c60d4b8873"
      },
      "outputs": [],
      "source": [
        "def pad_src_batch(src_batch: List[List[int]], src_seq_lens: List[int], pad_val: int):\n",
        "    \"\"\" Pad the batch for src sentences.\n",
        "        Note: Do not use append/extend that can modify the input inplace.\n",
        "    \n",
        "    Args:\n",
        "        src_batch: A list of src token ids\n",
        "        src_seq_lens: A list of src lens\n",
        "        pad_val: The padding value\n",
        "        \n",
        "    Returns:\n",
        "        src_batch: Tensor, (batch_size x max_len)\n",
        "        src_seq_lens_batch: Tensor, (batch_size, )\n",
        "    \"\"\"\n",
        "    max_src_len = max(src_seq_lens)\n",
        "    # Start your code here\n",
        "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
        "    # Padding\n",
        "    max_len = max(src_seq_lens)\n",
        "    padded_src = helper_function(src_batch, pad_val, max_len)\n",
        "    # Convert to tensor\n",
        "    src_batch = tf.convert_to_tensor(padded_src, dtype=tf.int64)\n",
        "    src_seq_lens_batch = tf.convert_to_tensor(src_seq_lens, dtype=tf.int64)\n",
        "    # End\n",
        "    return src_batch, src_seq_lens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "64baa751-3c5d-49e1-a80b-2efdbcb94bb9",
      "metadata": {
        "id": "64baa751-3c5d-49e1-a80b-2efdbcb94bb9"
      },
      "outputs": [],
      "source": [
        "def pad_tgt_batch(tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
        "    \"\"\" Pad the batch for tgt sentences.\n",
        "        Note: 1. Do not use append/extend that can modify the input inplace.\n",
        "              2. We need to build the x (feature) and y (label) for tgt sentences.\n",
        "                 Please understand what the feature and label are in translation.\n",
        "    \n",
        "    Args:\n",
        "        tgt_batch: A list of src token ids\n",
        "        tgt_seq_lens: A list of src lens\n",
        "        pad_val: The padding value\n",
        "        \n",
        "    Returns:\n",
        "        tgt_x_batch: Tensor, (batch_size x max_len)\n",
        "        tgt_y_batch: Tensor, (batch_size x max_len)\n",
        "        src_seq_lens_batch: Tensor, (batch_size, )\n",
        "    \"\"\"\n",
        "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = [], [], []\n",
        "    for sent, seq_len in zip(tgt_batch, tgt_seq_lens):\n",
        "        # Start your code here\n",
        "        # Append x, y, and seq_len\n",
        "        tgt_x_batch.append(sent[:-1])\n",
        "        tgt_y_batch.append(sent[1:])\n",
        "        tgt_seq_lens_batch.append(seq_len-1)\n",
        "        # End\n",
        "\n",
        "    max_tgt_len = max(tgt_seq_lens_batch)\n",
        "    # Start your code here\n",
        "    # Please refer to tf.convert_to_tensor. The dtype should be tf.int64\n",
        "    # Padding\n",
        "    padded_tgt_x = helper_function(tgt_x_batch, pad_val, max_tgt_len) \n",
        "    padded_tgt_y = helper_function(tgt_y_batch, pad_val, max_tgt_len) \n",
        "    # Convert to tensor\n",
        "    tgt_x_batch = tf.convert_to_tensor(padded_tgt_x, dtype=tf.int64)\n",
        "    tgt_y_batch = tf.convert_to_tensor(padded_tgt_y, dtype=tf.int64)\n",
        "    tgt_seq_lens_batch = tf.convert_to_tensor(tgt_seq_lens_batch, dtype=tf.int64)\n",
        "    # End\n",
        "    return tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a84ad89c-7f26-4bb4-a73b-0a19e7fa77c1",
      "metadata": {
        "id": "a84ad89c-7f26-4bb4-a73b-0a19e7fa77c1"
      },
      "outputs": [],
      "source": [
        "def pad_batch(src_batch: List[List[int]], src_seq_lens: List[int], tgt_batch: List[List[int]], tgt_seq_lens: List[int], pad_val: int):\n",
        "    src_batch, src_seq_lens_batch = pad_src_batch(src_batch, src_seq_lens, pad_val)\n",
        "    tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch = pad_tgt_batch(tgt_batch, tgt_seq_lens, pad_val)\n",
        "    return src_batch, src_seq_lens_batch, tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b6b26b-fac1-4bf1-a5b1-ae64b9ebbab5",
      "metadata": {
        "id": "e5b6b26b-fac1-4bf1-a5b1-ae64b9ebbab5"
      },
      "source": [
        "### 3.2 Batch Index Sampler (10 Points)\n",
        "\n",
        "Create a index sampler to sample data index for each batch.\n",
        "\n",
        "This is to make the sentences in each batch have similar lengths to speed up training.\n",
        "\n",
        "Example:\n",
        "```\n",
        "Assume the sentence lengths are: [5, 2, 3, 6, 2, 3, 6] and batch_size is 2.\n",
        "We can make the indices in the batches as follows:\n",
        "[1, 4] of length 2\n",
        "[2, 5] of length 3\n",
        "[0, 3] of lengths 5 and 6\n",
        "[6] of length 6\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9a3f5d5e-3429-4d25-a020-227de440d827",
      "metadata": {
        "id": "9a3f5d5e-3429-4d25-a020-227de440d827"
      },
      "outputs": [],
      "source": [
        "class SeqLenBatchSampler:\n",
        "    def __init__(self, seq_lens: List[int], batch_size: int, seed: int = 6666):\n",
        "        \"\"\" The index sampler.\n",
        "            It can be used with iteration:\n",
        "            ```\n",
        "            n_batch = len(sampler)\n",
        "            for indices in sampler:\n",
        "                ...\n",
        "            ```\n",
        "            \n",
        "            Args:\n",
        "                seq_lens: A list training sequence lengths (src)\n",
        "                batch_size: .\n",
        "                seed: .\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        self.seq_lens = seq_lens\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = self._make_batch_index()\n",
        "\n",
        "        self.n_batch = len(self.batches)\n",
        "        self.counter = -1\n",
        "        \n",
        "    def _make_batch_index(self) -> List[List[int]]:\n",
        "        \"\"\" Build the indexes in each batch.\n",
        "\n",
        "            Return:\n",
        "                batches: A list of indices batch, e.g., [[0, 2, 8], [3, 6, 4], [5, 1, 7], ...]\n",
        "        \"\"\"\n",
        "        n = len(self.seq_lens)\n",
        "        n_batch = int(np.ceil(n / self.batch_size))\n",
        "        batches = []\n",
        "        # Start your code here\n",
        "        # Step 1. Use np.argsort to get all indices with sorted length\n",
        "        #      2. Split the indices into batches using a for loop: `for i in range(n_batch):`\n",
        "        sorted_seq_lens = np.argsort(self.seq_lens)\n",
        "        for i in range(n_batch):\n",
        "            start = i*self.batch_size\n",
        "            end = start + self.batch_size\n",
        "            batches.append(sorted_seq_lens[start:end])\n",
        "        # End\n",
        "        return batches\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_batch\n",
        "    \n",
        "    def __item__(self, index):\n",
        "        return self.batches[index]\n",
        "    \n",
        "    def __iter__(self):\n",
        "        np.random.shuffle(self.batches)\n",
        "        self.counter = -1\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        self.counter += 1\n",
        "        if self.counter < self.n_batch:\n",
        "            return self.batches[self.counter]\n",
        "        raise StopIteration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43762b66-8820-4f21-9bf2-d59a82ae494f",
      "metadata": {
        "id": "43762b66-8820-4f21-9bf2-d59a82ae494f"
      },
      "source": [
        "### 3.3 Running the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25553751-af99-4ea1-9097-31bc0ba11b25",
      "metadata": {
        "id": "25553751-af99-4ea1-9097-31bc0ba11b25"
      },
      "source": [
        "Generate the length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d1b46b6e-6dde-4e49-9833-21b887faba1b",
      "metadata": {
        "id": "d1b46b6e-6dde-4e49-9833-21b887faba1b"
      },
      "outputs": [],
      "source": [
        "np.random.seed(6666)\n",
        "train_seq_lens_en = [len(en_sent) for en_sent in train_en]\n",
        "train_seq_lens_fr = [len(fr_sent) for fr_sent in train_fr]\n",
        "valid_seq_lens_en = [len(en_sent) for en_sent in valid_en]\n",
        "valid_seq_lens_fr = [len(fr_sent) for fr_sent in valid_fr]\n",
        "test_seq_lens_en = [len(en_sent) for en_sent in test_en]\n",
        "test_seq_lens_fr = [len(fr_sent) for fr_sent in test_fr]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3161d2df-c491-49a3-9d08-beb4b6b6f882",
      "metadata": {
        "id": "3161d2df-c491-49a3-9d08-beb4b6b6f882"
      },
      "source": [
        "Create np array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e2e974ea-136e-4111-b968-ca78d4c6dcf6",
      "metadata": {
        "id": "e2e974ea-136e-4111-b968-ca78d4c6dcf6"
      },
      "outputs": [],
      "source": [
        "train_en = np.array(train_en, dtype=object)\n",
        "train_seq_lens_en = np.array(train_seq_lens_en)\n",
        "train_fr = np.array(train_fr, dtype=object)\n",
        "train_seq_lens_fr = np.array(train_seq_lens_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63940225-535c-4463-8849-ba34f617be72",
      "metadata": {
        "id": "63940225-535c-4463-8849-ba34f617be72"
      },
      "source": [
        "Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "dcffb6b7-2704-422a-9a87-ee55d27fccad",
      "metadata": {
        "id": "dcffb6b7-2704-422a-9a87-ee55d27fccad"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "seed = 6666\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7d7a4641-950e-4edf-ac4a-68827a35cdc2",
      "metadata": {
        "id": "7d7a4641-950e-4edf-ac4a-68827a35cdc2"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = len(fr_tokenizer.get_vocab())\n",
        "tgt_vocab_size = len(en_tokenizer.get_vocab())\n",
        "hidden_units = 256\n",
        "embedding_dim = 128\n",
        "dropout_rate = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6be6a58a-22f2-4c82-8f1e-166fcf79698a",
      "metadata": {
        "id": "6be6a58a-22f2-4c82-8f1e-166fcf79698a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = Seq2seq(src_vocab_size, tgt_vocab_size, embedding_dim, hidden_units, dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e9a06051-90ff-49ee-8991-014bf0f9d2df",
      "metadata": {
        "id": "e9a06051-90ff-49ee-8991-014bf0f9d2df"
      },
      "outputs": [],
      "source": [
        "num_epoch = 15\n",
        "batch_size = 256\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "640af444-ef86-4ec3-861b-1c543a94a3b4",
      "metadata": {
        "id": "640af444-ef86-4ec3-861b-1c543a94a3b4"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "train_batch_sampler = SeqLenBatchSampler(train_seq_lens_fr, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "00f91312-ce07-4164-802e-c6379fc73e9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00f91312-ce07-4164-802e-c6379fc73e9c",
        "outputId": "d4edc73b-4739-441a-a61d-59f97366feaf",
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 15 - Step 910 / 910 - train loss: 5.9493 - valid loss: 5.6790\n",
            "Epoch 2 / 15 - Step 910 / 910 - train loss: 4.6868 - valid loss: 4.9340\n",
            "Epoch 3 / 15 - Step 910 / 910 - train loss: 4.0916 - valid loss: 4.6413\n",
            "Epoch 4 / 15 - Step 910 / 910 - train loss: 3.7614 - valid loss: 4.4748\n",
            "Epoch 5 / 15 - Step 910 / 910 - train loss: 3.5280 - valid loss: 4.3534\n",
            "Epoch 6 / 15 - Step 910 / 910 - train loss: 3.3459 - valid loss: 4.2683\n",
            "Epoch 7 / 15 - Step 910 / 910 - train loss: 3.1990 - valid loss: 4.1899\n",
            "Epoch 8 / 15 - Step 910 / 910 - train loss: 3.0759 - valid loss: 4.1546\n",
            "Epoch 9 / 15 - Step 910 / 910 - train loss: 2.9731 - valid loss: 4.1087\n",
            "Epoch 10 / 15 - Step 910 / 910 - train loss: 2.8839 - valid loss: 4.0884\n",
            "Epoch 11 / 15 - Step 910 / 910 - train loss: 2.8090 - valid loss: 4.0944\n",
            "Epoch 12 / 15 - Step 910 / 910 - train loss: 2.7395 - valid loss: 4.0519\n",
            "Epoch 13 / 15 - Step 910 / 910 - train loss: 2.6783 - valid loss: 4.0426\n",
            "Epoch 14 / 15 - Step 910 / 910 - train loss: 2.6254 - valid loss: 4.0278\n",
            "Epoch 15 / 15 - Step 910 / 910 - train loss: 2.5761 - valid loss: 4.0370\n"
          ]
        }
      ],
      "source": [
        "n_training_samples = len(train_fr)\n",
        "n_valid_batch = int(np.ceil(len(valid_fr) / batch_size))\n",
        "pad_token_id = fr_tokenizer.token_to_id('<pad>')\n",
        "train_losses, valid_losses = [], []\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_loss = 0.0\n",
        "    for batch_idx, data_index in enumerate(train_batch_sampler):\n",
        "        src_batch, src_seq_lens = train_fr[data_index], train_seq_lens_fr[data_index]\n",
        "        tgt_batch, tgt_seq_lens = train_en[data_index], train_seq_lens_en[data_index]\n",
        "        real_batch_size = len(src_batch)\n",
        "        (src_batch, src_seq_lens_batch,\n",
        "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
        "                                                                   tgt_batch, tgt_seq_lens,\n",
        "                                                                   pad_val=pad_token_id)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch)\n",
        "            loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
        "\n",
        "        print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {len(train_batch_sampler)} - loss: {loss:.4f}')\n",
        "\n",
        "        trainable_vars = model.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        epoch_loss += loss * real_batch_size\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    for batch_idx in range(n_valid_batch):\n",
        "        start = batch_idx * batch_size\n",
        "        end = start + batch_size\n",
        "        src_batch, src_seq_lens = valid_fr[start:end], valid_seq_lens_fr[start:end]\n",
        "        tgt_batch, tgt_seq_lens = valid_en[start:end], valid_seq_lens_en[start:end]\n",
        "        real_batch_size = len(src_batch)\n",
        "        (src_batch, src_seq_lens_batch,\n",
        "         tgt_x_batch, tgt_y_batch, tgt_seq_lens_batch) = pad_batch(src_batch, src_seq_lens,\n",
        "                                                                   tgt_batch, tgt_seq_lens,\n",
        "                                                                   pad_val=pad_token_id)\n",
        "        output = model(src_batch, src_seq_lens_batch, tgt_x_batch, tgt_seq_lens_batch, training=False)\n",
        "        loss = seq2seq_loss(output, tgt_y_batch, tgt_seq_lens_batch)\n",
        "\n",
        "        if batch_idx % 1 == 0 or batch_idx == len(valid_en) - 1:\n",
        "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
        "\n",
        "        valid_loss += loss * real_batch_size\n",
        "    train_epoch_loss = epoch_loss / n_training_samples\n",
        "    valid_epoch_loss = valid_loss / len(valid_en)\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    valid_losses.append(valid_epoch_loss)\n",
        "    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {len(train_batch_sampler)} / {len(train_batch_sampler)} - train loss: {train_epoch_loss:.4f} - valid loss: {valid_epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4767daac-7049-406e-a8ca-65d6ebeac90c",
      "metadata": {
        "id": "4767daac-7049-406e-a8ca-65d6ebeac90c"
      },
      "source": [
        "If you implement everything correctly, the valid loss will be around 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ff797bf0-b861-4c27-b64a-b470c1aaff86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff797bf0-b861-4c27-b64a-b470c1aaff86",
        "outputId": "ee603b47-655a-40e2-94aa-0fb336d830d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"seq2seq\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  1576448   \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| embedding (Embedding)     multiple                  1280000   |\n",
            "|                                                               |\n",
            "| gru (GRU)                 multiple                  296448    |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            " decoder (Decoder)           multiple                  4146448   \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| embedding_1 (Embedding)   multiple                  1280000   |\n",
            "|                                                               |\n",
            "| dropout (Dropout)         multiple                  0         |\n",
            "|                                                               |\n",
            "| gru_1 (GRU)               multiple                  296448    |\n",
            "|                                                               |\n",
            "| dense (Dense)             multiple                  2570000   |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            "=================================================================\n",
            "Total params: 5,722,896\n",
            "Trainable params: 5,722,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary(expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "87e55e2f-039f-44c2-880a-732300b252c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "87e55e2f-039f-44c2-880a-732300b252c4",
        "outputId": "f13e8789-aaae-4f7f-88f4-c5edb83bc815"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "x = np.arange(1, len(train_losses) + 1)\n",
        "plt.plot(x, train_losses, label='Train loss')\n",
        "plt.plot(x, valid_losses, label='Valid loss')\n",
        "plt.legend()\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(x)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48431b3c-a182-478e-a25d-011cb7680a1d",
      "metadata": {
        "id": "48431b3c-a182-478e-a25d-011cb7680a1d"
      },
      "source": [
        "### 3.4 Translate French to English (15 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "70cd07cb-43d1-40d4-994e-a6ae2b7d5be7",
      "metadata": {
        "id": "70cd07cb-43d1-40d4-994e-a6ae2b7d5be7"
      },
      "outputs": [],
      "source": [
        "sos_token_id = en_tokenizer.token_to_id('<s>')\n",
        "eos_token_id = en_tokenizer.token_to_id('</s>')\n",
        "max_pred_len = 200\n",
        "def translate(encoder: 'Encoder', decoder: 'Decoder', fr_sentences: List[List[int]]):\n",
        "    \"\"\" Translate the src (French) sentences to English sentences.\n",
        "        This is a recursive translation.\n",
        "        \n",
        "    Args:\n",
        "        encoder: The encoder part in seq2seq\n",
        "        decoder: The decoder part in seq2seq\n",
        "        fr_sentences: The src token ids of all sentences\n",
        "    Returns:\n",
        "        pred_sentences: The predicted string sentences\n",
        "    \"\"\"\n",
        "    n = len(fr_sentences)\n",
        "    pred_sentences = []\n",
        "    for i, src_ids in enumerate(fr_sentences):\n",
        "        print_line(f'{i + 1} / {n}')\n",
        "        # Shape of src_ids: (1 x seq_len)\n",
        "        src_ids = tf.expand_dims(tf.convert_to_tensor(src_ids, dtype=tf.int64), axis=0)\n",
        "        # pred is the prediction token ids. It starts with <s>\n",
        "        pred = [sos_token_id]\n",
        "        # Start your code here\n",
        "        # Step 1. Calculate the encoder outputs and hidden states (similar to seq2seq2 model)\n",
        "        # Step 2. Run a while loop when the last token in pred is not eos_token_id and the length of pred is less than max_pred_len\n",
        "        # Step 3.     In the while loop, build the input (cur_token) of decoder: the last token of pred. Shape (batch_size, ) -> (1, )\n",
        "        #             For example, if the current pred is [1, 50, 21, 8], the cur_token is [8]\n",
        "        # Step 4.     In the while loop, use decoder.predict to get the decoder output\n",
        "        # Step 5.     In the while loop, find the index with the maximum value. Then you can call tf.squeeze and numpy() to get the index\n",
        "        # Step 6.     In the while loop, append the predicted token to pred\n",
        "        # Step 7. Use en_tokenizer to decode the id to strings: pred_sentence\n",
        "        src_mask = src_ids != pad_token_id\n",
        "        encoder_output, final_state = encoder(src_ids, src_mask)\n",
        "        while ( (pred[-1] != eos_token_id) and (len(pred)< max_pred_len) ):\n",
        "          token = tf.reshape(tf.convert_to_tensor(pred[-1]),(1,))\n",
        "          dec_output,final_state = decoder.predict(tgt_ids = token, initial_state = final_state)\n",
        "          max_index = tf.math.argmax(dec_output[0]).numpy()\n",
        "          pred.append(max_index)\n",
        "        pred_sentence = en_tokenizer.decode(pred)\n",
        "        # End\n",
        "        pred_sentences.append(pred_sentence)\n",
        "    print_line('\\n')\n",
        "    return pred_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ce651b96-8127-4d76-a2e3-6c643d5cdfd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce651b96-8127-4d76-a2e3-6c643d5cdfd0",
        "outputId": "7fa625ac-e356-42e8-92ec-5c4c6d78aca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8597 / 8597\n"
          ]
        }
      ],
      "source": [
        "test_pred = translate(model.encoder, model.decoder, fr_sentences=test_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07764c0e-ef49-4475-8dd0-057d1fd21be1",
      "metadata": {
        "id": "07764c0e-ef49-4475-8dd0-057d1fd21be1"
      },
      "source": [
        "### 3.5 Demonstrate 10 translation examples (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "82a7812d-bd93-4eeb-8292-a7dca60beed4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82a7812d-bd93-4eeb-8292-a7dca60beed4",
        "outputId": "9eef9bc2-56fd-4d7a-dcd3-70ae44f5dcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fr: les bonnes équipes envoient ces informations de façon à ce que les joueurs puissent s'en servir.\n",
            "En: the good teams stream it in a way that the players can use.\n",
            "Pred_en:  the good ones that have these programs are actually using the information that they can do.\n",
            "\n",
            "\n",
            "Fr: merci.\n",
            "En: thank you.\n",
            "Pred_en:  thank you.\n",
            "\n",
            "\n",
            "Fr: il y a eu plusieurs cas où c'était vraiment juste.\n",
            "En: there have been several close calls.\n",
            "Pred_en:  there were many cases where it was really.\n",
            "\n",
            "\n",
            "Fr: mes prières vous accompagnent dans votre combat.\n",
            "En: my prayers are with you for your fight.\n",
            "Pred_en:  my prayer are going to be in my face in the fight.\n",
            "\n",
            "\n",
            "Fr: et la question était : comment la technologie pourrait, les nouvelles technologies, y être ajoutée ?\n",
            "En: and the question was: how could technology, new technology,  be added to that?\n",
            "Pred_en:  and the question was, how could technology be new technologies, could we be able to do this?\n",
            "\n",
            "\n",
            "Fr: combien d'entre vous ont vu l'ordinateur watson d'ibm gagner à jeopardy ?\n",
            "En: i mean, how many of you saw the winning of jeopardy  by ibm's watson?\n",
            "Pred_en:  how many of you have seen a computer program, you have to have a four-minute walk?\n",
            "\n",
            "\n",
            "Fr: j'ai travaillé dans une mine de charbon -- dangereux.\n",
            "En: i worked in a coal mine --  dangerous.\n",
            "Pred_en:  i worked in a nuclear farm.\n",
            "\n",
            "\n",
            "Fr: n'importe qui d'autre l'aimerait aussi.\n",
            "En: somebody else would love about this woman.\n",
            "Pred_en:  any other way in the other hand, it was like.\n",
            "\n",
            "\n",
            "Fr: c'est tragique que les nord-coréens aient à cacher leurs identités et affronter tant de choses seulement pour survivre.\n",
            "En: it's tragic that north koreans have to hide their identities  and struggle so hard just to survive.\n",
            "Pred_en:  it's been a cold-lived diet, and it's been to be the most important thing to do that for many people.\n",
            "\n",
            "\n",
            "Fr: la glace que je photographie dans les icebergs est parfois très jeune -- deux milles ans.\n",
            "En: some of the ice in the icebergs that i photograph is very young --  a couple thousand years old.\n",
            "Pred_en:  the ice i was in the mid-1800s, i was very young.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(6666)\n",
        "sample_num = 10\n",
        "# Start your code here\n",
        "# Use np.random.choice to sample 10 sentence indices. Remember to set correct replace\n",
        "# Print format:\n",
        "# 1.\n",
        "# French: ...\n",
        "# True English: ...\n",
        "# Translated English: ...\n",
        "# ------------------\n",
        "sent_indices = np.random.choice(a=len(test_fr_sentences), size=sample_num, replace = False)\n",
        "for i in range (len(sent_indices)):\n",
        "  print(f\"Fr: {test_fr_sentences [sent_indices[i]]}\")\n",
        "  print(f\"En: {test_en_sentences [sent_indices[i]]}\")\n",
        "  print(f\"Pred_en: {test_pred[sent_indices[i]]}\")\n",
        "  print(\"\\n\")\n",
        "# End"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a77aeb-c930-4553-9d4a-d5f72622af2c",
      "metadata": {
        "id": "92a77aeb-c930-4553-9d4a-d5f72622af2c"
      },
      "source": [
        "### 3.6 Compute the bleu score (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "e09d4b57-3015-427b-a6fd-d69139c29498",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e09d4b57-3015-427b-a6fd-d69139c29498",
        "outputId": "9dcf8c20-a803-4962-e279-c274441f0d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.67\n"
          ]
        }
      ],
      "source": [
        "from IPython.core import prefilter\n",
        "import evaluate\n",
        "\n",
        "\n",
        "sacrebleu = evaluate.load('sacrebleu', cache_dir=dataset_path)\n",
        "# Start your code here\n",
        "# see https://huggingface.co/spaces/evaluate-metric/sacrebleu\n",
        "# Note: please understand the format and meaning of references.\n",
        "\n",
        "n = len(test_en_sentences)\n",
        "references = list()\n",
        "predictions = []\n",
        "for i in range(n):\n",
        "  references.append([test_en_sentences[i]])\n",
        "  predictions.append(test_pred[i])\n",
        "results = sacrebleu.compute(predictions=predictions, references=references)\n",
        "# End\n",
        "score = results['score']\n",
        "print(round(score, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537d18a1-2fc3-4ea2-89be-6db4326a2d8f",
      "metadata": {
        "id": "537d18a1-2fc3-4ea2-89be-6db4326a2d8f"
      },
      "source": [
        "If you implement everything correctly, the BLEU score will be around 7."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8074e54-0b0d-45b7-87f9-2be1dc70532f",
      "metadata": {
        "id": "b8074e54-0b0d-45b7-87f9-2be1dc70532f"
      },
      "source": [
        "## Conclusion (5 Points)\n",
        "\n",
        "Including but not limited to: translation example analysis (case study), bleu score analysis, model structure / parameter analysis, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fbf908-27e5-4cba-a2d9-5ac308113c15",
      "metadata": {
        "id": "25fbf908-27e5-4cba-a2d9-5ac308113c15"
      },
      "source": [
        "Answer:\n",
        "- Through this assignment we got hands on experience of building Seq2Seq model to translated french sentences to english sentences and compared the translated ones with the original ones. \n",
        "- The model used to make these prediction has a total of 5,722,896 parameters all of with are trainiable \n",
        "- Encoder and the decoder were build using GRU layers. \n",
        "- We trained out own encoder and decoder for 15 epochs with a valid loss of around 4 and train loss of around 2\n",
        "- The model is evaluated the Bleu score which is an evaluation metric for  evaluating machine-translated text. It measures the similarity of the machine-translated text to a set of reference translations. In this case we get a score of 7\n",
        "- The model performace fairly well in some case like with the following example the prediction accurately match the ground truth.\n",
        "```\n",
        "Fr: merci.\n",
        "En: thank you.\n",
        "Pred_en:  thank you.\n",
        "```\n",
        "- We can also see some of the cases that are far from the truth value, like as follows\n",
        "```\n",
        "Fr: mes prières vous accompagnent dans votre combat.\n",
        "En: my prayers are with you for your fight.\n",
        "Pred_en:  my wish to be brought in from you to fight.\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3530a74f-e2c7-493d-8fa0-ce8c925f973d",
        "29a10839-398f-421c-aac3-d189d61c2982",
        "da95576b-60df-4537-b696-f02bb84507c8",
        "a1720c69-2fd3-4310-b850-9ce9036bfe23",
        "a240b136-ca49-4fc8-ab34-5bc2516cadad",
        "79ddf45c-adb4-449d-9a5a-052512e5ff97",
        "e5b6b26b-fac1-4bf1-a5b1-ae64b9ebbab5",
        "43762b66-8820-4f21-9bf2-d59a82ae494f",
        "48431b3c-a182-478e-a25d-011cb7680a1d",
        "07764c0e-ef49-4475-8dd0-057d1fd21be1",
        "92a77aeb-c930-4553-9d4a-d5f72622af2c"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "account_details",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, May 24 2022, 21:28:31) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "318b20e5e552330ac64402a63c1a3d538eebc51f858fc08a88a1f9c9a530966c"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "233335dd716e499aa4434216e56bcc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc31a2a40fc84c48b817d2add157747e",
              "IPY_MODEL_31633a0cf6c84beb9c397666f856e45c",
              "IPY_MODEL_e343b79e8e1c45ff88f7958e5abf7636"
            ],
            "layout": "IPY_MODEL_9218b33f8a5446f5b21eddefccb68b76"
          }
        },
        "2a528f37252a4feead4e9b1879c0d03f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31633a0cf6c84beb9c397666f856e45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a233c673f745159fa9e79bd639fa1e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_504b22b39b5745109e34a8a787f3af66",
            "value": 3
          }
        },
        "504b22b39b5745109e34a8a787f3af66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62a233c673f745159fa9e79bd639fa1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79177f1279684b7ab416c4d4ace8beb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f4a1a68a75f47149e748db8a4a7c645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "807566af41b44a089264a5e3ece63e98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9218b33f8a5446f5b21eddefccb68b76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e343b79e8e1c45ff88f7958e5abf7636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a528f37252a4feead4e9b1879c0d03f",
            "placeholder": "​",
            "style": "IPY_MODEL_7f4a1a68a75f47149e748db8a4a7c645",
            "value": " 3/3 [00:00&lt;00:00, 68.68it/s]"
          }
        },
        "fc31a2a40fc84c48b817d2add157747e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_807566af41b44a089264a5e3ece63e98",
            "placeholder": "​",
            "style": "IPY_MODEL_79177f1279684b7ab416c4d4ace8beb3",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
